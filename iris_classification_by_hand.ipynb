{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1097,
   "id": "a9aed070",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7288cf",
   "metadata": {},
   "source": [
    "## Logistic Regression Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1098,
   "id": "c0a1c204",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1.0 / (1.0 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1099,
   "id": "b8b3012f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_gradient(theta, X, y):\n",
    "    m = y.size      # This is the number of instances\n",
    "    return (X.T @ (sigmoid(X @ theta) - y)) / m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1100,
   "id": "7e023877",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, alpha=0.1, num_iterations=100, tol=1e-7):\n",
    "    X_bias = np.c_[np.ones((X.shape[0], 1)), X]\n",
    "\n",
    "    theta = np.zeros(X_bias.shape[1])\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "        gradient = calculate_gradient(theta, X_bias, y)\n",
    "        theta -= alpha * gradient\n",
    "\n",
    "        if np.linalg.norm(gradient) < tol:\n",
    "            break\n",
    "\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1101,
   "id": "627758f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_proba(X, theta):\n",
    "    X_bias = np.c_[np.ones((X.shape[0], 1)), X]\n",
    "\n",
    "    return sigmoid(X_bias @ theta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1102,
   "id": "3ec00b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, theta, threshold=0.5):\n",
    "    return (predict_proba(X, theta) >= threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1103,
   "id": "cda635f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1104,
   "id": "f6e88efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data = load_iris()\n",
    "X, y = iris_data.data, iris_data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1105,
   "id": "26ac2176",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1106,
   "id": "35f7e035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 3 separate binary classifiers\n",
      "    Training classifier for class 0 (setosa) vs the rest\n",
      "    Training classifier for class 1 (versicolor) vs the rest\n",
      "    Training classifier for class 2 (virginica) vs the rest\n",
      "Training complete\n"
     ]
    }
   ],
   "source": [
    "# Training one classifier for each class using the One Vs Rest method (class 0 or non-class 0 and so on)\n",
    "all_thetas = []\n",
    "num_classes = len(np.unique(y))     # There are 3 unique classes in the Iris dataset\n",
    "\n",
    "print(f\"Training {num_classes} separate binary classifiers\")\n",
    "\n",
    "for i in range(num_classes):\n",
    "    # Create a temporary target vector for this specific class\n",
    "    y_train_specific = (y_train == i).astype(int)\n",
    "\n",
    "    print(f\"    Training classifier for class {i} ({iris_data.target_names[i]}) vs the rest\")\n",
    "\n",
    "    # Using the gradient descent function to train the binary classifier\n",
    "    theta_hat = gradient_descent(X_train_scaled, y_train_specific, alpha=0.1, num_iterations=1000)\n",
    "\n",
    "    # Store the trained parameters\n",
    "    all_thetas.append(theta_hat)\n",
    "\n",
    "print(\"Training complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1107,
   "id": "c05ff0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ovr(X, thetas):\n",
    "    probabilities = np.array([predict_proba(X, theta) for theta in thetas]).T\n",
    "\n",
    "    return np.argmax(probabilities, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1108,
   "id": "1964719d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Accuracy: 0.9667\n",
      "\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        10\n",
      "  versicolor       1.00      0.89      0.94         9\n",
      "   virginica       0.92      1.00      0.96        11\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.97      0.96      0.97        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predictions on the test set\n",
    "y_pred = predict_ovr(X_test_scaled, all_thetas)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nModel Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Classification report for a more detailed look\n",
    "print(\"\\nClassification report\")\n",
    "print(classification_report(y_test, y_pred, target_names=iris_data.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c63277",
   "metadata": {},
   "source": [
    "## K Nearest Neighbors (KNN) Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1109,
   "id": "c0d2947d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1110,
   "id": "b45d46ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_euclidean_dist(p, q):\n",
    "    # This is a np.array of every value in p - every value in q\n",
    "    #np.array(p) - np.array(q)\n",
    "\n",
    "    return np.sqrt(np.sum((np.array(p) - np.array(q)) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1111,
   "id": "da54ca71",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNeighborsClassifier:\n",
    "    def __init__(self, k=3):\n",
    "        self.k = k\n",
    "\n",
    "    def fit(self, X_trian, y_train):\n",
    "        self.X_train = X_trian\n",
    "        self.y_train = y_train\n",
    "\n",
    "    def predict_single(self, x_test_point):\n",
    "        '''Helper function to predict the label of one single data point'''\n",
    "\n",
    "        # Calculate the distance to all training points\n",
    "        distances = [calc_euclidean_dist(x_test_point, x_train_point) for x_train_point in self.X_train]\n",
    "\n",
    "        # Get the indices of the k nearest neighbors\n",
    "        k_neigbors_indices = np.argsort(distances)[:self.k]\n",
    "\n",
    "        # Get the labels of the neighbors\n",
    "        k_neigbors_labels = [self.y_train[i] for i in k_neigbors_indices]\n",
    "\n",
    "        # Return the most common class label \n",
    "        most_common = Counter(k_neigbors_labels).most_common(1)\n",
    "        return most_common[0][0]\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        '''Makes predictions for a set of test data'''\n",
    "        \n",
    "        # Loop through each test point and predict its label\n",
    "        preds = [self.predict_single(x_test_point) for x_test_point in X_test]\n",
    "        return np.array(preds)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1112,
   "id": "82cc4967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading and preparing the data\n",
    "iris_data = load_iris()\n",
    "X, y = iris_data.data, iris_data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scld = scaler.fit_transform(X_train)\n",
    "X_test_scld = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1113,
   "id": "37ae551a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the KNN classifier\n",
    "knn_classifier = KNeighborsClassifier(k=5)\n",
    "\n",
    "knn_classifier.fit(X_train_scld, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_predictions = knn_classifier.predict(X_test_scld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1114,
   "id": "b8345637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN model accuracy: 0.9333\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        13\n",
      "  versicolor       0.88      0.88      0.88         8\n",
      "   virginica       0.89      0.89      0.89         9\n",
      "\n",
      "    accuracy                           0.93        30\n",
      "   macro avg       0.92      0.92      0.92        30\n",
      "weighted avg       0.93      0.93      0.93        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "acc = accuracy_score(y_test, y_predictions)\n",
    "\n",
    "print(f\"KNN model accuracy: {acc:.4f}\\n\")\n",
    "\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, y_predictions, target_names=iris_data.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26d960c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Iris_Classification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
